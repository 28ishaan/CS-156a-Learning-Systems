{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKo5ldOAffst"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hoeffding Inequality"
      ],
      "metadata": {
        "id": "2h1vEnnpRt8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flip_1000():\n",
        "  result = []\n",
        "  all_coins = []\n",
        "\n",
        "  lowest_freq = 1.0\n",
        "  c_1_index = 0\n",
        "  c_min_index = 0\n",
        "  c_rand_index = random.randint(0,999)\n",
        "\n",
        "  # Flip 1000 coins\n",
        "  for x in range(1000):\n",
        "    # For each coin\n",
        "    curr_coin = []\n",
        "    curr_headcount = 0\n",
        "    # Flip 10 times\n",
        "    for x in range(10):\n",
        "      flip = random.randint(0,1)\n",
        "      # If heads, increment headcount\n",
        "      if(flip == 1):\n",
        "        curr_headcount += 1\n",
        "      # Add the flip to the coin\n",
        "      curr_coin.append(flip)\n",
        "    # if the curr_coin frequency is less than the lowest, update it\n",
        "    if((curr_headcount / 10.0) < lowest_freq):\n",
        "      lowest_freq = (curr_headcount / 10.0)\n",
        "      c_min_index = x\n",
        "    # Add the current coin to all the coins\n",
        "    all_coins.append(curr_coin)\n",
        "  c_1 = all_coins[c_1_index]\n",
        "  c_rand = all_coins[c_rand_index]\n",
        "  c_min = all_coins[c_min_index]\n",
        "\n",
        "  v_1 = c_1.count(1) / 10.0\n",
        "  v_rand = c_rand.count(1) / 10.0\n",
        "  v_min = lowest_freq\n",
        "\n",
        "  return v_1, v_rand, v_min"
      ],
      "metadata": {
        "id": "jBbUfVLnftBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_v_1 = []\n",
        "all_v_rand = []\n",
        "all_v_min = []\n",
        "\n",
        "n = 10000\n",
        "for x in range(n):\n",
        "  v_1, v_rand, v_min = flip_1000()\n",
        "  all_v_1.append(v_1)\n",
        "  all_v_rand.append(v_rand)\n",
        "  all_v_min.append(v_min)\n",
        "\n",
        "v_min_avg = sum(all_v_min) / n\n",
        "print(f'Average Value of v_min: {v_min_avg}\\n\\n')\n",
        "print(\"V_1, V_rand, V_min Distributions\\n\")\n",
        "\n",
        "fig, axis = plt.subplots(3)\n",
        "\n",
        "axis[0].hist(all_v_1, bins=np.linspace(0, 10, 11)/10)\n",
        "# axis[0].title(\"V_1 Distribution\")\n",
        "\n",
        "axis[1].hist(all_v_rand, bins=np.linspace(0, 10, 11)/10)\n",
        "# axis[1].title(\"V_rand Distribution\")\n",
        "\n",
        "axis[2].hist(all_v_min, bins=np.linspace(0, 10, 11)/10)\n",
        "# axis[2].title(\"V_min Distribution\")\n",
        "\n",
        "plt.xlabel(\"Percentage of Heads\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "AR3LBJhzgu6R",
        "outputId": "e77f5cf1-197d-4635-ff26-188bcfe2c9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Value of v_min: 0.03747000000000167\n",
            "\n",
            "\n",
            "V_1, V_rand, V_min Distributions\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGwCAYAAAC3qV8qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDU0lEQVR4nO3deXRUZbr2/ysJVCVAKmEwk0aZGgFFFJAYERTNS5RIi43HATqgjSBt6H4hyhChCYJHODjR0gitqPGsFwXsBtomdCAEAweIopHYjFEgCDZUkEZSASHj8/uDH3UoCUPFpCo7fj9r1VrUs5+96953hrrYQyXAGGMEAABgIYH+LgAAAMBbBBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5TfxdQH2prq7W4cOHFRoaqoCAAH+XAwAAroAxRqWlpYqJiVFg4MWPszTaAHP48GHFxsb6uwwAAFALhw4d0jXXXHPR5Y02wISGhko62wCHw+HnagAAwJVwuVyKjY11v49fTKMNMOdOGzkcDgIMAAAWc7nLP7iIFwAAWA4BBgAAWE6jPYUEoHFrOznT3yV47cDsJH+XADQaHIEBAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACW41WAmTVrlm699VaFhoYqIiJCgwcPVmFhocecM2fOKCUlRa1bt1aLFi00ZMgQFRcXe8w5ePCgkpKS1KxZM0VERGjChAmqrKz0mJObm6sePXrIbrerY8eOysjIqN0eAgCARqeJN5M3bNiglJQU3XrrraqsrNRzzz2nAQMGaNeuXWrevLkkafz48crMzNSHH36osLAwjR07Vr/61a+0efNmSVJVVZWSkpIUFRWlLVu26MiRIxo+fLiaNm2qF198UZJUVFSkpKQkjRkzRosXL1ZOTo6efPJJRUdHKzExsY5bAAC+0XZypr9L8NqB2Un+LgGoUYAxxtR25e+++04RERHasGGD+vXrp5KSEl111VV6//339dBDD0mS9uzZoy5duigvL0+33Xab/vGPf+j+++/X4cOHFRkZKUlauHChJk2apO+++042m02TJk1SZmamduzY4X6tRx99VCdOnFBWVlaNtZSVlamsrMz93OVyKTY2ViUlJXI4HLXdRQANlBXDgBURYOBrLpdLYWFhl33/9uoIzI+VlJRIklq1aiVJys/PV0VFhRISEtxzOnfurGuvvdYdYPLy8tStWzd3eJGkxMRE/fa3v9XOnTt1yy23KC8vz2Mb5+aMGzfuorXMmjVLzz///E/ZHeBnizAAwGpqfRFvdXW1xo0bpz59+ujGG2+UJDmdTtlsNoWHh3vMjYyMlNPpdM85P7ycW35u2aXmuFwunT59usZ60tLSVFJS4n4cOnSotrsGAAAauFofgUlJSdGOHTu0adOmuqyn1ux2u+x2u7/LAAAAPlCrIzBjx47VqlWr9PHHH+uaa65xj0dFRam8vFwnTpzwmF9cXKyoqCj3nB/flXTu+eXmOBwOhYSE1KZkAADQiHgVYIwxGjt2rFasWKH169erXbt2Hst79uyppk2bKicnxz1WWFiogwcPKj4+XpIUHx+v7du36+jRo+452dnZcjgc6tq1q3vO+ds4N+fcNgAAwM+bV6eQUlJS9P777+tvf/ubQkND3deshIWFKSQkRGFhYRo5cqRSU1PVqlUrORwO/e53v1N8fLxuu+02SdKAAQPUtWtXJScna86cOXI6nZo6dapSUlLcp4DGjBmjP/3pT5o4caJ+85vfaP369Vq2bJkyM7nQEAAAeHkEZsGCBSopKdFdd92l6Oho92Pp0qXuOa+99pruv/9+DRkyRP369VNUVJSWL1/uXh4UFKRVq1YpKChI8fHx+vWvf63hw4drxowZ7jnt2rVTZmamsrOz1b17d73yyitatGgRnwEDAAAk/cTPgWnIrvQ+cgDcRo2L43Ng4GtX+v7N30ICAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACWQ4ABAACW08TfBQAAGq62kzP9XYLXDsxO8ncJ8AECDFDHrPgLHwCshlNIAADAcggwAADAcrwOMBs3btSgQYMUExOjgIAArVy50mO5MUbTpk1TdHS0QkJClJCQoK+//tpjzvHjxzVs2DA5HA6Fh4dr5MiROnnypMecf/7zn+rbt6+Cg4MVGxurOXPmeL93AACgUfI6wJw6dUrdu3fX/Pnza1w+Z84cvf7661q4cKE+/fRTNW/eXImJiTpz5ox7zrBhw7Rz505lZ2dr1apV2rhxo0aPHu1e7nK5NGDAAF133XXKz8/XSy+9pOnTp+vNN9+sxS4CAIDGJsAYY2q9ckCAVqxYocGDB0s6e/QlJiZGzzzzjJ599llJUklJiSIjI5WRkaFHH31Uu3fvVteuXfXZZ5+pV69ekqSsrCwNHDhQ3377rWJiYrRgwQJNmTJFTqdTNptNkjR58mStXLlSe/bsuaLaXC6XwsLCVFJSIofDUdtdBLzGRbyAf3EXkrVd6ft3nV4DU1RUJKfTqYSEBPdYWFiY4uLilJeXJ0nKy8tTeHi4O7xIUkJCggIDA/Xpp5+65/Tr188dXiQpMTFRhYWF+v7772t87bKyMrlcLo8HAABonOo0wDidTklSZGSkx3hkZKR7mdPpVEREhMfyJk2aqFWrVh5zatrG+a/xY7NmzVJYWJj7ERsb+9N3CAAANEiN5i6ktLQ0lZSUuB+HDh3yd0kAAKCe1GmAiYqKkiQVFxd7jBcXF7uXRUVF6ejRox7LKysrdfz4cY85NW3j/Nf4MbvdLofD4fEAAACNU50GmHbt2ikqKko5OTnuMZfLpU8//VTx8fGSpPj4eJ04cUL5+fnuOevXr1d1dbXi4uLcczZu3KiKigr3nOzsbF1//fVq2bJlXZYMAAAsyOsAc/LkSRUUFKigoEDS2Qt3CwoKdPDgQQUEBGjcuHF64YUX9NFHH2n79u0aPny4YmJi3HcqdenSRffee69GjRqlrVu3avPmzRo7dqweffRRxcTESJKGDh0qm82mkSNHaufOnVq6dKn++Mc/KjU1tc52HAAAWJfXfwvp888/V//+/d3Pz4WKESNGKCMjQxMnTtSpU6c0evRonThxQnfccYeysrIUHBzsXmfx4sUaO3as7rnnHgUGBmrIkCF6/fXX3cvDwsK0du1apaSkqGfPnmrTpo2mTZvm8VkxAADg5+snfQ5MQ8bnwMBf+BwYwL/4HBhr88vnwAAAAPgCAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFhOE38XAFxK28mZ/i4BANAAEWAAAI2KFf/jc2B2kr9LsBxOIQEAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMvhjzkCAOBn/AFK7zXoADN//ny99NJLcjqd6t69u+bNm6fevXv7uyxLsuIPBwAAF9NgTyEtXbpUqampSk9P1xdffKHu3bsrMTFRR48e9XdpAADAzxpsgHn11Vc1atQoPfHEE+ratasWLlyoZs2a6Z133vF3aQAAwM8a5Cmk8vJy5efnKy0tzT0WGBiohIQE5eXl1bhOWVmZysrK3M9LSkokSS6Xq87ruzF9TZ1vEwAAK6mP99fzt2uMueS8Bhlgjh07pqqqKkVGRnqMR0ZGas+ePTWuM2vWLD3//PMXjMfGxtZLjQAA/JyFza3f7ZeWliosLOyiyxtkgKmNtLQ0paamup9XV1fr+PHjat26tQICAursdVwul2JjY3Xo0CE5HI462y4uRK99gz77Bn32DfrsG/XZZ2OMSktLFRMTc8l5DTLAtGnTRkFBQSouLvYYLy4uVlRUVI3r2O122e12j7Hw8PD6KlEOh4MfDh+h175Bn32DPvsGffaN+urzpY68nNMgL+K12Wzq2bOncnJy3GPV1dXKyclRfHy8HysDAAANQYM8AiNJqampGjFihHr16qXevXtr7ty5OnXqlJ544gl/lwYAAPyswQaYRx55RN99952mTZsmp9Opm2++WVlZWRdc2Otrdrtd6enpF5yuQt2j175Bn32DPvsGffaNhtDnAHO5+5QAAAAamAZ5DQwAAMClEGAAAIDlEGAAAIDlEGAAAIDlEGBqMH/+fLVt21bBwcGKi4vT1q1bLzn/ww8/VOfOnRUcHKxu3bpp9erVPqrU+rzp9VtvvaW+ffuqZcuWatmypRISEi77tcFZ3n5Pn7NkyRIFBARo8ODB9VtgI+Ftn0+cOKGUlBRFR0fLbrerU6dO/P64At72ee7cubr++usVEhKi2NhYjR8/XmfOnPFRtda0ceNGDRo0SDExMQoICNDKlSsvu05ubq569Oghu92ujh07KiMjo36LNPCwZMkSY7PZzDvvvGN27txpRo0aZcLDw01xcXGN8zdv3myCgoLMnDlzzK5du8zUqVNN06ZNzfbt231cufV42+uhQ4ea+fPnm23btpndu3ebxx9/3ISFhZlvv/3Wx5Vbi7d9PqeoqMhcffXVpm/fvuaBBx7wTbEW5m2fy8rKTK9evczAgQPNpk2bTFFRkcnNzTUFBQU+rtxavO3z4sWLjd1uN4sXLzZFRUVmzZo1Jjo62owfP97HlVvL6tWrzZQpU8zy5cuNJLNixYpLzt+/f79p1qyZSU1NNbt27TLz5s0zQUFBJisrq95qJMD8SO/evU1KSor7eVVVlYmJiTGzZs2qcf7DDz9skpKSPMbi4uLMU089Va91Ngbe9vrHKisrTWhoqHnvvffqq8RGoTZ9rqysNLfffrtZtGiRGTFiBAHmCnjb5wULFpj27dub8vJyX5XYKHjb55SUFHP33Xd7jKWmppo+ffrUa52NyZUEmIkTJ5obbrjBY+yRRx4xiYmJ9VYXp5DOU15ervz8fCUkJLjHAgMDlZCQoLy8vBrXycvL85gvSYmJiRedj7Nq0+sf++GHH1RRUaFWrVrVV5mWV9s+z5gxQxERERo5cqQvyrS82vT5o48+Unx8vFJSUhQZGakbb7xRL774oqqqqnxVtuXUps+333678vPz3aeZ9u/fr9WrV2vgwIE+qfnnwh/vhQ32k3j94dixY6qqqrrg034jIyO1Z8+eGtdxOp01znc6nfVWZ2NQm17/2KRJkxQTE3PBDw3+V236vGnTJr399tsqKCjwQYWNQ236vH//fq1fv17Dhg3T6tWrtXfvXj399NOqqKhQenq6L8q2nNr0eejQoTp27JjuuOMOGWNUWVmpMWPG6LnnnvNFyT8bF3svdLlcOn36tEJCQur8NTkCA0uaPXu2lixZohUrVig4ONjf5TQapaWlSk5O1ltvvaU2bdr4u5xGrbq6WhEREXrzzTfVs2dPPfLII5oyZYoWLlzo79IaldzcXL344ot644039MUXX2j58uXKzMzUzJkz/V0afiKOwJynTZs2CgoKUnFxscd4cXGxoqKialwnKirKq/k4qza9Pufll1/W7NmztW7dOt100031Wabledvnffv26cCBAxo0aJB7rLq6WpLUpEkTFRYWqkOHDvVbtAXV5vs5OjpaTZs2VVBQkHusS5cucjqdKi8vl81mq9earag2ff7DH/6g5ORkPfnkk5Kkbt266dSpUxo9erSmTJmiwED+H18XLvZe6HA46uXoi8QRGA82m009e/ZUTk6Oe6y6ulo5OTmKj4+vcZ34+HiP+ZKUnZ190fk4qza9lqQ5c+Zo5syZysrKUq9evXxRqqV52+fOnTtr+/btKigocD9++ctfqn///iooKFBsbKwvy7eM2nw/9+nTR3v37nUHREn66quvFB0dTXi5iNr0+YcffrggpJwLjYY/BVhn/PJeWG+XB1vUkiVLjN1uNxkZGWbXrl1m9OjRJjw83DidTmOMMcnJyWby5Mnu+Zs3bzZNmjQxL7/8stm9e7dJT0/nNuor5G2vZ8+ebWw2m/nLX/5ijhw54n6Ulpb6axcswds+/xh3IV0Zb/t88OBBExoaasaOHWsKCwvNqlWrTEREhHnhhRf8tQuW4G2f09PTTWhoqPnggw/M/v37zdq1a02HDh3Mww8/7K9dsITS0lKzbds2s23bNiPJvPrqq2bbtm3mm2++McYYM3nyZJOcnOyef+426gkTJpjdu3eb+fPncxu1P8ybN89ce+21xmazmd69e5tPPvnEvezOO+80I0aM8Ji/bNky06lTJ2Oz2cwNN9xgMjMzfVyxdXnT6+uuu85IuuCRnp7u+8Itxtvv6fMRYK6ct33esmWLiYuLM3a73bRv397853/+p6msrPRx1dbjTZ8rKirM9OnTTYcOHUxwcLCJjY01Tz/9tPn+++99X7iFfPzxxzX+vj3X2xEjRpg777zzgnVuvvlmY7PZTPv27c27775brzUGGNM4j6FVV1fr8OHDCg0NVUBAgL/LAQAAV8AYo9LSUsXExFzyGqVGexHv4cOHOV8PAIBFHTp0SNdcc81FlzfaABMaGirpbAMcDoefqwEAAFfC5XIpNjbW/T5+MY02wJw7beRwOAgwAABYzOUu/+A2agAAYDkEGAAAYDmN9hQSgMat7eRMf5fgtQOzk/xdAtBocAQGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYjlcBZtasWbr11lsVGhqqiIgIDR48WIWFhR5zzpw5o5SUFLVu3VotWrTQkCFDVFxc7DHn4MGDSkpKUrNmzRQREaEJEyaosrLSY05ubq569Oghu92ujh07KiMjo3Z7CAAAGh2vAsyGDRuUkpKiTz75RNnZ2aqoqNCAAQN06tQp95zx48fr73//uz788ENt2LBBhw8f1q9+9Sv38qqqKiUlJam8vFxbtmzRe++9p4yMDE2bNs09p6ioSElJSerfv78KCgo0btw4Pfnkk1qzZk0d7DIAALC6AGOMqe3K3333nSIiIrRhwwb169dPJSUluuqqq/T+++/roYcekiTt2bNHXbp0UV5enm677Tb94x//0P3336/Dhw8rMjJSkrRw4UJNmjRJ3333nWw2myZNmqTMzEzt2LHD/VqPPvqoTpw4oaysrCuqzeVyKSwsTCUlJXI4HLXdRQANVNvJmf4uwWsHZif5uwSgwbvS9+8mP+VFSkpKJEmtWrWSJOXn56uiokIJCQnuOZ07d9a1117rDjB5eXnq1q2bO7xIUmJion77299q586duuWWW5SXl+exjXNzxo0bd9FaysrKVFZW5n7ucrl+yq4BPytWDANWZMU+E7rQUNX6It7q6mqNGzdOffr00Y033ihJcjqdstlsCg8P95gbGRkpp9PpnnN+eDm3/NyyS81xuVw6ffp0jfXMmjVLYWFh7kdsbGxtdw0AADRwtQ4wKSkp2rFjh5YsWVKX9dRaWlqaSkpK3I9Dhw75uyQAAFBPanUKaezYsVq1apU2btyoa665xj0eFRWl8vJynThxwuMoTHFxsaKiotxztm7d6rG9c3cpnT/nx3cuFRcXy+FwKCQkpMaa7Ha77HZ7bXYHAABYjFdHYIwxGjt2rFasWKH169erXbt2Hst79uyppk2bKicnxz1WWFiogwcPKj4+XpIUHx+v7du36+jRo+452dnZcjgc6tq1q3vO+ds4N+fcNgAAwM+bV0dgUlJS9P777+tvf/ubQkND3deshIWFKSQkRGFhYRo5cqRSU1PVqlUrORwO/e53v1N8fLxuu+02SdKAAQPUtWtXJScna86cOXI6nZo6dapSUlLcR1DGjBmjP/3pT5o4caJ+85vfaP369Vq2bJkyM613ARwAAKh7Xh2BWbBggUpKSnTXXXcpOjra/Vi6dKl7zmuvvab7779fQ4YMUb9+/RQVFaXly5e7lwcFBWnVqlUKCgpSfHy8fv3rX2v48OGaMWOGe067du2UmZmp7Oxsde/eXa+88ooWLVqkxMTEOthlAABgdT/pc2AaMj4HBrhyVry9F77BbdTwtSt9/+ZvIQEAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMshwAAAAMtp4u8CgMam7eRMf5cA1Bkrfj8fmJ3k7xLgAxyBAQAAlkOAAQAAluN1gNm4caMGDRqkmJgYBQQEaOXKlR7LjTGaNm2aoqOjFRISooSEBH399dcec44fP65hw4bJ4XAoPDxcI0eO1MmTJz3m/POf/1Tfvn0VHBys2NhYzZkzx/u9AwAAjZLXAebUqVPq3r275s+fX+PyOXPm6PXXX9fChQv16aefqnnz5kpMTNSZM2fcc4YNG6adO3cqOztbq1at0saNGzV69Gj3cpfLpQEDBui6665Tfn6+XnrpJU2fPl1vvvlmLXYRAAA0NgHGGFPrlQMCtGLFCg0ePFjS2aMvMTExeuaZZ/Tss89KkkpKShQZGamMjAw9+uij2r17t7p27arPPvtMvXr1kiRlZWVp4MCB+vbbbxUTE6MFCxZoypQpcjqdstlskqTJkydr5cqV2rNnzxXV5nK5FBYWppKSEjkcjtruIuA1K170CDQmXMRrbVf6/l2n18AUFRXJ6XQqISHBPRYWFqa4uDjl5eVJkvLy8hQeHu4OL5KUkJCgwMBAffrpp+45/fr1c4cXSUpMTFRhYaG+//77Gl+7rKxMLpfL4wEAABqnOg0wTqdTkhQZGekxHhkZ6V7mdDoVERHhsbxJkyZq1aqVx5yatnH+a/zYrFmzFBYW5n7Exsb+9B0CAAANUqO5CyktLU0lJSXux6FDh/xdEgAAqCd1GmCioqIkScXFxR7jxcXF7mVRUVE6evSox/LKykodP37cY05N2zj/NX7MbrfL4XB4PAAAQONUpwGmXbt2ioqKUk5OjnvM5XLp008/VXx8vCQpPj5eJ06cUH5+vnvO+vXrVV1drbi4OPecjRs3qqKiwj0nOztb119/vVq2bFmXJQMAAAvyOsCcPHlSBQUFKigokHT2wt2CggIdPHhQAQEBGjdunF544QV99NFH2r59u4YPH66YmBj3nUpdunTRvffeq1GjRmnr1q3avHmzxo4dq0cffVQxMTGSpKFDh8pms2nkyJHauXOnli5dqj/+8Y9KTU2tsx0HAADW5fXfQvr888/Vv39/9/NzoWLEiBHKyMjQxIkTderUKY0ePVonTpzQHXfcoaysLAUHB7vXWbx4scaOHat77rlHgYGBGjJkiF5//XX38rCwMK1du1YpKSnq2bOn2rRpo2nTpnl8VgwAAPj5+kmfA9OQ8Tkw8Bc+BwbwLz4Hxtr88jkwAAAAvkCAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAltPE3wUAl9J2cqa/SwAANEAcgQEAAJbDERgAQKNixSO3B2Yn+bsEy+EIDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBz+mCMAAH7GH6D0XoMOMPPnz9dLL70kp9Op7t27a968eerdu7e/y7IkK/5wAABwMQ32FNLSpUuVmpqq9PR0ffHFF+revbsSExN19OhRf5cGAAD8rMEegXn11Vc1atQoPfHEE5KkhQsXKjMzU++8844mT558wfyysjKVlZW5n5eUlEiSXC6Xbwpu4KrLfvB3CQCARqS+3l/PbdcYc8l5DTLAlJeXKz8/X2lpae6xwMBAJSQkKC8vr8Z1Zs2apeeff/6C8djY2HqrEwCAn6uwufW7/dLSUoWFhV10eYMMMMeOHVNVVZUiIyM9xiMjI7Vnz54a10lLS1Nqaqr7eXV1tY4fP67WrVsrICCgzmpzuVyKjY3VoUOH5HA46my7uBC99g367Bv02Tfos2/UZ5+NMSotLVVMTMwl5zXIAFMbdrtddrvdYyw8PLzeXs/hcPDD4SP02jfos2/QZ9+gz75RX32+1JGXcxrkRbxt2rRRUFCQiouLPcaLi4sVFRXlp6oAAEBD0SADjM1mU8+ePZWTk+Meq66uVk5OjuLj4/1YGQAAaAga7Cmk1NRUjRgxQr169VLv3r01d+5cnTp1yn1Xkr/Y7Xalp6dfcLoKdY9e+wZ99g367Bv02TcaQp8DzOXuU/KjP/3pT+4Psrv55pv1+uuvKy4uzt9lAQAAP2vQAQYAAKAmDfIaGAAAgEshwAAAAMshwAAAAMshwAAAAMshwNRg/vz5atu2rYKDgxUXF6etW7decv6HH36ozp07Kzg4WN26ddPq1at9VKn1edPrt956S3379lXLli3VsmVLJSQkXPZrg7O8/Z4+Z8mSJQoICNDgwYPrt8BGwts+nzhxQikpKYqOjpbdblenTp34/XEFvO3z3Llzdf311yskJESxsbEaP368zpw546NqrWnjxo0aNGiQYmJiFBAQoJUrV152ndzcXPXo0UN2u10dO3ZURkZG/RZp4GHJkiXGZrOZd955x+zcudOMGjXKhIeHm+Li4hrnb9682QQFBZk5c+aYXbt2malTp5qmTZua7du3+7hy6/G210OHDjXz588327ZtM7t37zaPP/64CQsLM99++62PK7cWb/t8TlFRkbn66qtN3759zQMPPOCbYi3M2z6XlZWZXr16mYEDB5pNmzaZoqIik5ubawoKCnxcubV42+fFixcbu91uFi9ebIqKisyaNWtMdHS0GT9+vI8rt5bVq1ebKVOmmOXLlxtJZsWKFZecv3//ftOsWTOTmppqdu3aZebNm2eCgoJMVlZWvdVIgPmR3r17m5SUFPfzqqoqExMTY2bNmlXj/IcfftgkJSV5jMXFxZmnnnqqXutsDLzt9Y9VVlaa0NBQ895779VXiY1CbfpcWVlpbr/9drNo0SIzYsQIAswV8LbPCxYsMO3btzfl5eW+KrFR8LbPKSkp5u677/YYS01NNX369KnXOhuTKwkwEydONDfccIPH2COPPGISExPrrS5OIZ2nvLxc+fn5SkhIcI8FBgYqISFBeXl5Na6Tl5fnMV+SEhMTLzofZ9Wm1z/2ww8/qKKiQq1ataqvMi2vtn2eMWOGIiIiNHLkSF+UaXm16fNHH32k+Ph4paSkKDIyUjfeeKNefPFFVVVV+apsy6lNn2+//Xbl5+e7TzPt379fq1ev1sCBA31S88+FP94LG+yfEvCHY8eOqaqqSpGRkR7jkZGR2rNnT43rOJ3OGuc7nc56q7MxqE2vf2zSpEmKiYm54IcG/6s2fd60aZPefvttFRQU+KDCxqE2fd6/f7/Wr1+vYcOGafXq1dq7d6+efvppVVRUKD093RdlW05t+jx06FAdO3ZMd9xxh4wxqqys1JgxY/Tcc8/5ouSfjYu9F7pcLp0+fVohISF1/pocgYElzZ49W0uWLNGKFSsUHBzs73IajdLSUiUnJ+utt95SmzZt/F1Oo1ZdXa2IiAi9+eab6tmzpx555BFNmTJFCxcu9HdpjUpubq5efPFFvfHGG/riiy+0fPlyZWZmaubMmf4uDT8RR2DO06ZNGwUFBam4uNhjvLi4WFFRUTWuExUV5dV8nFWbXp/z8ssva/bs2Vq3bp1uuumm+izT8rzt8759+3TgwAENGjTIPVZdXS1JatKkiQoLC9WhQ4f6LdqCavP9HB0draZNmyooKMg91qVLFzmdTpWXl8tms9VrzVZUmz7/4Q9/UHJysp588klJUrdu3XTq1CmNHj1aU6ZMUWAg/4+vCxd7L3Q4HPVy9EXiCIwHm82mnj17Kicnxz1WXV2tnJwcxcfH17hOfHy8x3xJys7Ovuh8nFWbXkvSnDlzNHPmTGVlZalXr16+KNXSvO1z586dtX37dhUUFLgfv/zlL9W/f38VFBQoNjbWl+VbRm2+n/v06aO9e/e6A6IkffXVV4qOjia8XERt+vzDDz9cEFLOhUbDnwKsM355L6y3y4MtasmSJcZut5uMjAyza9cuM3r0aBMeHm6cTqcxxpjk5GQzefJk9/zNmzebJk2amJdfftns3r3bpKencxv1FfK217NnzzY2m8385S9/MUeOHHE/SktL/bULluBtn3+Mu5CujLd9PnjwoAkNDTVjx441hYWFZtWqVSYiIsK88MIL/toFS/C2z+np6SY0NNR88MEHZv/+/Wbt2rWmQ4cO5uGHH/bXLlhCaWmp2bZtm9m2bZuRZF599VWzbds288033xhjjJk8ebJJTk52zz93G/WECRPM7t27zfz58+v9NupGewqpurpahw8fVmhoqAICAq54vfvuu08zZ87U1KlTVVxcrJtuukl//etfFRISIpfLpf3796uyslIul0uSdOONN2rRokWaOXOm0tLS1KFDB73//vu69tpr3XNQM297PX/+fJWXl+uhhx7y2M7kyZOVlpbmj12wBG/7/GPl5eWqqKjg+/kyvO1zWFiYli9frsmTJ+vNN99UTEyMnnrqKT399NP0+hK87fPvf/97lZWV6bnnntPhw4fVpk0b3XffffrDH/5Any/hf/7nf3T//fe7n6empkqSHnvsMS1cuFDffPONDh486O5h69attWzZMqWlpWnu3Lm6+uqrNW/ePMXHx3vdZ2OMSktLFRMTc8lTfAHGNM5jaN9++y2HuwEAsKhDhw7pmmuuuejyRnsEJjQ0VNLZBjgcDj9XAwAAroTL5VJsbKz7ffxiGm2AOXfayOFwEGAAALCYy13+wV1IAADAcggwAADAchrtKaT61HZypr9L8NqB2Un+LgEAgDrDERgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5XgWY6dOnKyAgwOPRuXNn9/IzZ84oJSVFrVu3VosWLTRkyBAVFxd7bOPgwYNKSkpSs2bNFBERoQkTJqiystJjTm5urnr06CG73a6OHTsqIyOj9nsIAAAaHa+PwNxwww06cuSI+7Fp0yb3svHjx+vvf/+7PvzwQ23YsEGHDx/Wr371K/fyqqoqJSUlqby8XFu2bNF7772njIwMTZs2zT2nqKhISUlJ6t+/vwoKCjRu3Dg9+eSTWrNmzU/cVQAA0Fg08XqFJk0UFRV1wXhJSYnefvttvf/++7r77rslSe+++666dOmiTz75RLfddpvWrl2rXbt2ad26dYqMjNTNN9+smTNnatKkSZo+fbpsNpsWLlyodu3a6ZVXXpEkdenSRZs2bdJrr72mxMTEn7i7AACgMfD6CMzXX3+tmJgYtW/fXsOGDdPBgwclSfn5+aqoqFBCQoJ7bufOnXXttdcqLy9PkpSXl6du3bopMjLSPScxMVEul0s7d+50zzl/G+fmnNvGxZSVlcnlcnk8AABA4+RVgImLi1NGRoaysrK0YMECFRUVqW/fviotLZXT6ZTNZlN4eLjHOpGRkXI6nZIkp9PpEV7OLT+37FJzXC6XTp8+fdHaZs2apbCwMPcjNjbWm10DAAAW4tUppPvuu8/975tuuklxcXG67rrrtGzZMoWEhNR5cd5IS0tTamqq+7nL5SLEAADQSP2k26jDw8PVqVMn7d27V1FRUSovL9eJEyc85hQXF7uvmYmKirrgrqRzzy83x+FwXDIk2e12ORwOjwcAAGicflKAOXnypPbt26fo6Gj17NlTTZs2VU5Ojnt5YWGhDh48qPj4eElSfHy8tm/frqNHj7rnZGdny+FwqGvXru4552/j3Jxz2wAAAPAqwDz77LPasGGDDhw4oC1btujBBx9UUFCQHnvsMYWFhWnkyJFKTU3Vxx9/rPz8fD3xxBOKj4/XbbfdJkkaMGCAunbtquTkZH355Zdas2aNpk6dqpSUFNntdknSmDFjtH//fk2cOFF79uzRG2+8oWXLlmn8+PF1v/cAAMCSvLoG5ttvv9Vjjz2mf//737rqqqt0xx136JNPPtFVV10lSXrttdcUGBioIUOGqKysTImJiXrjjTfc6wcFBWnVqlX67W9/q/j4eDVv3lwjRozQjBkz3HPatWunzMxMjR8/Xn/84x91zTXXaNGiRdxCDQAA3AKMMcbfRdQHl8ulsLAwlZSU1Pn1MG0nZ9bp9nzhwOwkf5cAAMBlXen7N38LCQAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWE4TfxcA32g7OdPfJdTKgdlJ/i4BANAAcQQGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYDgEGAABYjlcBZtasWbr11lsVGhqqiIgIDR48WIWFhR5z7rrrLgUEBHg8xowZ4zHn4MGDSkpKUrNmzRQREaEJEyaosrLSY05ubq569Oghu92ujh07KiMjo3Z7CAAAGh2vAsyGDRuUkpKiTz75RNnZ2aqoqNCAAQN06tQpj3mjRo3SkSNH3I85c+a4l1VVVSkpKUnl5eXasmWL3nvvPWVkZGjatGnuOUVFRUpKSlL//v1VUFCgcePG6cknn9SaNWt+4u4CAIDGoIk3k7OysjyeZ2RkKCIiQvn5+erXr597vFmzZoqKiqpxG2vXrtWuXbu0bt06RUZG6uabb9bMmTM1adIkTZ8+XTabTQsXLlS7du30yiuvSJK6dOmiTZs26bXXXlNiYmKN2y0rK1NZWZn7ucvl8mbXAACAhfyka2BKSkokSa1atfIYX7x4sdq0aaMbb7xRaWlp+uGHH9zL8vLy1K1bN0VGRrrHEhMT5XK5tHPnTvechIQEj20mJiYqLy/vorXMmjVLYWFh7kdsbOxP2TUAANCAeXUE5nzV1dUaN26c+vTpoxtvvNE9PnToUF133XWKiYnRP//5T02aNEmFhYVavny5JMnpdHqEF0nu506n85JzXC6XTp8+rZCQkAvqSUtLU2pqqvu5y+UixAAA0EjVOsCkpKRox44d2rRpk8f46NGj3f/u1q2boqOjdc8992jfvn3q0KFD7Su9DLvdLrvdXm/bBwAADUetTiGNHTtWq1at0scff6xrrrnmknPj4uIkSXv37pUkRUVFqbi42GPOuefnrpu52ByHw1Hj0RcAAPDz4lWAMcZo7NixWrFihdavX6927dpddp2CggJJUnR0tCQpPj5e27dv19GjR91zsrOz5XA41LVrV/ecnJwcj+1kZ2crPj7em3IBAEAj5VWASUlJ0f/7f/9P77//vkJDQ+V0OuV0OnX69GlJ0r59+zRz5kzl5+frwIED+uijjzR8+HD169dPN910kyRpwIAB6tq1q5KTk/Xll19qzZo1mjp1qlJSUtyngMaMGaP9+/dr4sSJ2rNnj9544w0tW7ZM48ePr+PdBwAAVuRVgFmwYIFKSkp01113KTo62v1YunSpJMlms2ndunUaMGCAOnfurGeeeUZDhgzR3//+d/c2goKCtGrVKgUFBSk+Pl6//vWvNXz4cM2YMcM9p127dsrMzFR2dra6d++uV155RYsWLbroLdQAAODnJcAYY/xdRH1wuVwKCwtTSUmJHA5HnW677eTMOt0eLu7A7CR/lwAA8KErff/mbyEBAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLadABZv78+Wrbtq2Cg4MVFxenrVu3+rskAADQADTYALN06VKlpqYqPT1dX3zxhbp3767ExEQdPXrU36UBAAA/a7AB5tVXX9WoUaP0xBNPqGvXrlq4cKGaNWumd955x9+lAQAAP2vi7wJqUl5ervz8fKWlpbnHAgMDlZCQoLy8vBrXKSsrU1lZmft5SUmJJMnlctV5fdVlP9T5NlGz+vj6AQAarnO/940xl5zXIAPMsWPHVFVVpcjISI/xyMhI7dmzp8Z1Zs2apeeff/6C8djY2HqpEb4RNtffFQAA/KG0tFRhYWEXXd4gA0xtpKWlKTU11f28urpax48fV+vWrRUQEFBnr+NyuRQbG6tDhw7J4XDU2XZxIXrtG/TZN+izb9Bn36jPPhtjVFpaqpiYmEvOa5ABpk2bNgoKClJxcbHHeHFxsaKiompcx263y263e4yFh4fXV4lyOBz8cPgIvfYN+uwb9Nk36LNv1FefL3Xk5ZwGeRGvzWZTz549lZOT4x6rrq5WTk6O4uPj/VgZAABoCBrkERhJSk1N1YgRI9SrVy/17t1bc+fO1alTp/TEE0/4uzQAAOBnDTbAPPLII/ruu+80bdo0OZ1O3XzzzcrKyrrgwl5fs9vtSk9Pv+B0FeoevfYN+uwb9Nk36LNvNIQ+B5jL3acEAADQwDTIa2AAAAAuhQADAAAshwADAAAshwADAAAshwBTg/nz56tt27YKDg5WXFyctm7desn5H374oTp37qzg4GB169ZNq1ev9lGl1udNr9966y317dtXLVu2VMuWLZWQkHDZrw3O8vZ7+pwlS5YoICBAgwcPrt8CGwlv+3zixAmlpKQoOjpadrtdnTp14vfHFfC2z3PnztX111+vkJAQxcbGavz48Tpz5oyPqrWmjRs3atCgQYqJiVFAQIBWrlx52XVyc3PVo0cP2e12dezYURkZGfVbpIGHJUuWGJvNZt555x2zc+dOM2rUKBMeHm6Ki4trnL9582YTFBRk5syZY3bt2mWmTp1qmjZtarZv3+7jyq3H214PHTrUzJ8/32zbts3s3r3bPP744yYsLMx8++23Pq7cWrzt8zlFRUXm6quvNn379jUPPPCAb4q1MG/7XFZWZnr16mUGDhxoNm3aZIqKikxubq4pKCjwceXW4m2fFy9ebOx2u1m8eLEpKioya9asMdHR0Wb8+PE+rtxaVq9ebaZMmWKWL19uJJkVK1Zccv7+/ftNs2bNTGpqqtm1a5eZN2+eCQoKMllZWfVWIwHmR3r37m1SUlLcz6uqqkxMTIyZNWtWjfMffvhhk5SU5DEWFxdnnnrqqXqtszHwttc/VllZaUJDQ817771XXyU2CrXpc2Vlpbn99tvNokWLzIgRIwgwV8DbPi9YsMC0b9/elJeX+6rERsHbPqekpJi7777bYyw1NdX06dOnXutsTK4kwEycONHccMMNHmOPPPKISUxMrLe6OIV0nvLycuXn5yshIcE9FhgYqISEBOXl5dW4Tl5ensd8SUpMTLzofJxVm17/2A8//KCKigq1atWqvsq0vNr2ecaMGYqIiNDIkSN9Uabl1abPH330keLj45WSkqLIyEjdeOONevHFF1VVVeWrsi2nNn2+/fbblZ+f7z7NtH//fq1evVoDBw70Sc0/F/54L2ywn8TrD8eOHVNVVdUFn/YbGRmpPXv21LiO0+mscb7T6ay3OhuD2vT6xyZNmqSYmJgLfmjwv2rT502bNuntt99WQUGBDypsHGrT5/3792v9+vUaNmyYVq9erb179+rpp59WRUWF0tPTfVG25dSmz0OHDtWxY8d0xx13yBijyspKjRkzRs8995wvSv7ZuNh7ocvl0unTpxUSElLnr8kRGFjS7NmztWTJEq1YsULBwcH+LqfRKC0tVXJyst566y21adPG3+U0atXV1YqIiNCbb76pnj176pFHHtGUKVO0cOFCf5fWqOTm5urFF1/UG2+8oS+++ELLly9XZmamZs6c6e/S8BNxBOY8bdq0UVBQkIqLiz3Gi4uLFRUVVeM6UVFRXs3HWbXp9Tkvv/yyZs+erXXr1ummm26qzzItz9s+79u3TwcOHNCgQYPcY9XV1ZKkJk2aqLCwUB06dKjfoi2oNt/P0dHRatq0qYKCgtxjXbp0kdPpVHl5uWw2W73WbEW16fMf/vAHJScn68knn5QkdevWTadOndLo0aM1ZcoUBQby//i6cLH3QofDUS9HXySOwHiw2Wzq2bOncnJy3GPV1dXKyclRfHx8jevEx8d7zJek7Ozsi87HWbXptSTNmTNHM2fOVFZWlnr16uWLUi3N2z537txZ27dvV0FBgfvxy1/+Uv3791dBQYFiY2N9Wb5l1Ob7uU+fPtq7d687IErSV199pejoaMLLRdSmzz/88MMFIeVcaDT8KcA645f3wnq7PNiilixZYux2u8nIyDC7du0yo0ePNuHh4cbpdBpjjElOTjaTJ092z9+8ebNp0qSJefnll83u3btNeno6t1FfIW97PXv2bGOz2cxf/vIXc+TIEfejtLTUX7tgCd72+ce4C+nKeNvngwcPmtDQUDN27FhTWFhoVq1aZSIiIswLL7zgr12wBG/7nJ6ebkJDQ80HH3xg9u/fb9auXWs6dOhgHn74YX/tgiWUlpaabdu2mW3bthlJ5tVXXzXbtm0z33zzjTHGmMmTJ5vk5GT3/HO3UU+YMMHs3r3bzJ8/n9uo/WHevHnm2muvNTabzfTu3dt88skn7mV33nmnGTFihMf8ZcuWmU6dOhmbzWZuuOEGk5mZ6eOKrcubXl933XVG0gWP9PR03xduMd5+T5+PAHPlvO3zli1bTFxcnLHb7aZ9+/bmP//zP01lZaWPq7Yeb/pcUVFhpk+fbjp06GCCg4NNbGysefrpp83333/v+8It5OOPP67x9+253o4YMcLceeedF6xz8803G5vNZtq3b2/efffdeq0xwBiOoQEAAGvhGhgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgAAGA5BBgA+P9Nnz5dkZGRCggI0MqVK/1dTo3uuusujRs3zt9lAH5HgAEasMcff1wBAQEKCAiQzWZTx44dNWPGDFVWVvq7tMtqyCGgJrt379bzzz+vP//5zzpy5Ijuu+++C+YcOHBAAQEBKigouGAZwQLwrSb+LgDApd1777169913VVZWptWrVyslJUVNmzZVWlqa19uqqqpSQEDABX+dF9K+ffskSQ888IACAgL8XA2Ay+G3GNDA2e12RUVF6brrrtNvf/tbJSQk6KOPPpIklZWV6dlnn9XVV1+t5s2bKy4uTrm5ue51MzIyFB4ero8++khdu3aV3W7XwYMHVVZWpkmTJik2NlZ2u10dO3bU22+/7V5vx44duu+++9SiRQtFRkYqOTlZx44dcy+/66679Pvf/14TJ05Uq1atFBUVpenTp7uXt23bVpL04IMPKiAgwP183759euCBBxQZGakWLVro1ltv1bp16zz298iRI0pKSlJISIjatWun999/X23bttXcuXPdc06cOKEnn3xSV111lRwOh+6++259+eWXl+zj9u3bdffddyskJEStW7fW6NGjdfLkSUlnTx0NGjRIkhQYGFgnAeZyX5t///vfeuyxx3T11VerWbNm6tatmz744AOPbZw6dUrDhw9XixYtFB0drVdeeeWC13njjTf0i1/8QsHBwYqMjNRDDz30k2sHrIAAA1hMSEiIysvLJUljx45VXl6elixZon/+85/6j//4D9177736+uuv3fN/+OEH/dd//ZcWLVqknTt3KiIiQsOHD9cHH3yg119/Xbt379af//xntWjRQtLZcHD33Xfrlltu0eeff66srCwVFxfr4Ycf9qjjvffeU/PmzfXpp59qzpw5mjFjhrKzsyVJn332mSTp3Xff1ZEjR9zPT548qYEDByonJ0fbtm3Tvffeq0GDBungwYPu7Q4fPlyHDx9Wbm6u/vrXv+rNN9/U0aNHPV77P/7jP3T06FH94x//UH5+vnr06KF77rlHx48fr7Fnp06dUmJiolq2bKnPPvtMH374odatW6exY8dKkp599lm9++67ks4GqCNHjtTui3Oey31tzpw5o549eyozM1M7duzQ6NGjlZycrK1bt7q3MWHCBG3YsEF/+9vftHbtWuXm5uqLL75wL//888/1+9//XjNmzFBhYaGysrLUr1+/n1w7YAn1+reuAfwkI0aMMA888IAxxpjq6mqTnZ1t7Ha7efbZZ80333xjgoKCzL/+9S+Pde655x6TlpZmjDHm3XffNZJMQUGBe3lhYaGRZLKzs2t8zZkzZ5oBAwZ4jB06dMhIMoWFhcYYY+68805zxx13eMy59dZbzaRJk9zPJZkVK1Zcdh9vuOEGM2/ePGOMMbt37zaSzGeffeZe/vXXXxtJ5rXXXjPGGPM///M/xuFwmDNnznhsp0OHDubPf/5zja/x5ptvmpYtW5qTJ0+6xzIzM01gYKBxOp3GGGNWrFhhLvcrsaioyEgyISEhpnnz5h6PwMBA83//7/81xpgr+trUJCkpyTzzzDPGGGNKS0uNzWYzy5Ytcy//97//bUJCQtyv89e//tU4HA7jcrkuWTfQGHENDNDArVq1Si1atFBFRYWqq6s1dOhQTZ8+Xbm5uaqqqlKnTp085peVlal169bu5zabTTfddJP7eUFBgYKCgnTnnXfW+HpffvmlPv74Y/cRmfPt27fP/Xrnb1OSoqOjLzhS8mMnT57U9OnTlZmZqSNHjqiyslKnT592H4EpLCxUkyZN1KNHD/c6HTt2VMuWLT3qO3nypMc+StLp06fd17H82O7du9W9e3c1b97cPdanTx9VV1ersLBQkZGRl6z7x5YuXaouXbp4jA0bNsz97+3bt1/2a1NVVaUXX3xRy5Yt07/+9S+Vl5errKxMzZo1k3S21+Xl5YqLi3Ov36pVK11//fXu5//n//wfXXfddWrfvr3uvfde3XvvvXrwwQfd2wAaMwIM0MD1799fCxYskM1mU0xMjJo0Oftje/LkSQUFBSk/P19BQUEe65wfPkJCQjyu6QgJCbnk6508eVKDBg3Sf/3Xf12wLDo62v3vpk2beiwLCAhQdXX1Jbf97LPPKjs7Wy+//LI6duyokJAQPfTQQ+5TYlfi5MmTio6O9rie5Jzw8PAr3s5PERsbq44dO3qMnd/XK/navPTSS/rjH/+ouXPnqlu3bmrevLnGjRvnVS9CQ0P1xRdfKDc3V2vXrtW0adM0ffp0ffbZZz7rBeAvBBiggWvevPkFb5aSdMstt6iqqkpHjx5V3759r3h73bp1U3V1tTZs2KCEhIQLlvfo0UN//etf1bZtW3dYqo2mTZuqqqrKY2zz5s16/PHH9eCDD0o6+0Z/4MAB9/Lrr79elZWV2rZtm3r27ClJ2rt3r77//nuP+pxOp5o0aeK+OPhyunTpooyMDJ06dcp9FGbz5s0KDAz0OKJRV67ka7N582Y98MAD+vWvfy1Jqq6u1ldffaWuXbtKkjp06KCmTZvq008/1bXXXitJ+v777/XVV195HD1r0qSJEhISlJCQoPT0dIWHh2v9+vX61a9+Vef7BTQkXMQLWFSnTp00bNgwDR8+XMuXL1dRUZG2bt2qWbNmKTMz86LrtW3bViNGjNBvfvMbrVy5UkVFRcrNzdWyZcskSSkpKTp+/Lgee+wxffbZZ9q3b5/WrFmjJ5544oJAcilt27ZVTk6OnE6nO4D84he/0PLly1VQUKAvv/xSQ4cO9Thq07lzZyUkJGj06NHaunWrtm3bptGjR3scRUpISFB8fLwGDx6stWvX6sCBA9qyZYumTJmizz//vMZahg0bpuDgYI0YMUI7duzQxx9/rN/97ndKTk72+vTRlbiSr80vfvELZWdna8uWLdq9e7eeeuopFRcXu7fRokULjRw5UhMmTND69eu1Y8cOPf744x63wK9atUqvv/66CgoK9M033+i///u/VV1dXS+hDGhoCDCAhb377rsaPny4nnnmGV1//fUaPHiwPvvsM/f/2C9mwYIFeuihh/T000+rc+fOGjVqlE6dOiVJiomJ0ebNm1VVVaUBAwaoW7duGjdunMLDw736/JhXXnlF2dnZio2N1S233CJJevXVV9WyZUvdfvvtGjRokBITEz2ud5Gk//7v/1ZkZKT69eunBx98UKNGjVJoaKiCg4MlnT1VtXr1avXr109PPPGEOnXqpEcffVTffPPNRcNIs2bNtGbNGh0/fly33nqrHnroId1zzz3605/+dMX7463LfW2mTp2qHj16KDExUXfddZeioqI0ePBgj2289NJL6tu3rwYNGqSEhATdcccd7iNT0tlTZsuXL9fdd9+tLl26aOHChfrggw90ww031Nt+AQ1FgDHG+LsIALiYb7/9VrGxsVq3bp3uuecef5cDoIEgwABoUNavX6+TJ0+qW7duOnLkiCZOnKh//etf+uqrry64cBjAzxcX8QJoUCoqKvTcc89p//79Cg0N1e23367FixcTXgB44AgMAACwHC7iBQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlvP/AR9FOll2oo/XAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. b**\n",
        "the average value of v_min is closest to 0.01."
      ],
      "metadata": {
        "id": "RDK4c5oZRBs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. d**\n",
        "For the distribution to satisfy the single-bin Hoeffding Inequality, it must be binomial. Only v_1 and v_rand satisfy this requirement."
      ],
      "metadata": {
        "id": "g_E6KT9oRMtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error and Noise"
      ],
      "metadata": {
        "id": "ARZcK_TgRotw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. e**\n",
        "Let $\\mu$ = the probability that $h$ makes an error in approximating $f$ and $λ$ = the probability that y = $f(x)$. There are two cases in which an error occurs.\n",
        "1. $h$ makes an error, but y is correct.\n",
        "2. $h$ does not make an error, but y is incorrect.\n",
        "\n",
        "The probability of case 1 occuring is $\\mu*λ$. The probability of case 2 occuring is $(1-\\mu)*(1-λ)$. Thus, the total probability of error is $(\\mu*λ)+(1-\\mu)*(1-λ)$"
      ],
      "metadata": {
        "id": "Qbd5KDbdSYcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. b**\n",
        "If we expand the previous equation, we get $P = \\muλ + (1-\\mu-λ+\\muλ) = 1 - \\mu - λ + 2\\muλ$. Rearranging the equation such that $\\mu$ terms are together, we get $P = 1-λ + \\mu(2λ-1)$. For the performace of $h$ to be independent of $\\mu$, we can plug in $λ = 0.5$. From this, we get $P = 1 - 0.5 = 0.5$"
      ],
      "metadata": {
        "id": "VKybd6_0Tn4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "7-heits5VHtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "USLjmtqnVbfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rand_points():\n",
        "  p1 = (random.uniform(-1,1), random.uniform(-1,1))\n",
        "  p2 = (random.uniform(-1,1), random.uniform(-1,1))\n",
        "  return p1, p2\n",
        "\n",
        "def get_target_function():\n",
        "  p1, p2 = get_rand_points()\n",
        "  slope = (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
        "  intercept = p2[1] - (slope * p2[0])\n",
        "  return (slope, intercept)\n"
      ],
      "metadata": {
        "id": "VzejNPhDViI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 100\n",
        "runs = 1000\n",
        "\n",
        "g = []\n",
        "E_in = []\n",
        "for i in range(runs):\n",
        "    p1, p2 = get_rand_points()\n",
        "    tar_func = get_target_function()\n",
        "    m = tar_func[0]\n",
        "    b = tar_func[1]\n",
        "\n",
        "    x = np.random.uniform(-1, 1, size=(n,2))\n",
        "\n",
        "    def y_func(x:np.ndarray):\n",
        "        return np.sign(m*x[0]-x[1]+b).astype(int)\n",
        "\n",
        "    y = np.apply_along_axis(y_func, 1, x)\n",
        "\n",
        "    model = LinearRegression().fit(x, y)\n",
        "    g.append(model)\n",
        "\n",
        "    eIn = np.bincount(np.sign(model.predict(x)).astype(int) == y)[0] / len(x)\n",
        "    E_in.append(eIn)\n",
        "\n",
        "sum(E_in) / runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX5BoQlCagFG",
        "outputId": "43f35c45-ded6-4fcf-9ff5-625211426b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03978000000000008"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. c**\n",
        "The output is closest to 0.01."
      ],
      "metadata": {
        "id": "iUnR7rYv_ije"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = 1000\n",
        "E_out = []\n",
        "\n",
        "for _ in range(runs):\n",
        "    p1, p2 = get_rand_points()\n",
        "    tar_func = get_target_function()\n",
        "    m = tar_func[0]\n",
        "    b = tar_func[1]\n",
        "    x = np.random.uniform(-1, 1, size=(n,2))\n",
        "\n",
        "    def y_func(x:np.ndarray):\n",
        "        return np.sign(m*x[0]-x[1]+b).astype(int)\n",
        "\n",
        "    y = np.apply_along_axis(y_func, 1, x)\n",
        "\n",
        "    model = LinearRegression().fit(x, y)\n",
        "\n",
        "    new_points = 1000\n",
        "    x_new = np.random.uniform(-1, 1, size=(new_points, 2))\n",
        "    y_new = np.apply_along_axis(y_func, 1, x_new)\n",
        "\n",
        "    eOut = np.bincount(np.sign(model.predict(x_new)).astype(int) == y_new)[0] / len(x_new)\n",
        "    E_out.append(eOut)\n",
        "\n",
        "sum(E_out) / runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHkeoy4l_gi-",
        "outputId": "8544ac30-7d32-4a45-d80b-37ace7ce273a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04930399999999996"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. c**\n",
        "The output is closest to 0.01."
      ],
      "metadata": {
        "id": "ltqHNedfBFlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def g(point: np.ndarray, weights: np.ndarray) -> int:\n",
        "    return np.sign( np.dot( np.transpose(weights), point ) ).astype(int)\n",
        "\n",
        "def converges():\n",
        "    for i,point in enumerate(XWithBias):\n",
        "        if g(point, linear_regression_weights) != Y[i]:\n",
        "            return False\n",
        "    numIterationsList.append(counter)"
      ],
      "metadata": {
        "id": "vwOLfYn7Hpqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "runs = 1000\n",
        "\n",
        "numIterationsList = []\n",
        "\n",
        "for _ in range(runs):\n",
        "    p1, p2 = get_rand_points()\n",
        "    tar_func = get_target_function()\n",
        "    m = tar_func[0]\n",
        "    b = tar_func[1]\n",
        "\n",
        "    weightsForF = np.array([b, m, -1])\n",
        "    X = np.random.uniform(-1, 1, size=(n,2))\n",
        "    XWithBias = np.insert(x, 0, 1, axis=1)\n",
        "    Y = np.sign(np.dot(XWithBias, weightsForF))\n",
        "\n",
        "    XDagger = np.dot(np.linalg.inv(np.dot(XWithBias.T, XWithBias)), XWithBias.T)\n",
        "    linear_regression_weights = np.dot(XDagger, Y)\n",
        "\n",
        "    counter = 0\n",
        "    while not converges():\n",
        "        counter += 1\n",
        "        correctNs = []\n",
        "        wrongNs = []\n",
        "\n",
        "        for i,point in enumerate(XWithBias):\n",
        "            if g(point,linear_regression_weights) == y[i]:\n",
        "                correctNs.append(i)\n",
        "            else:\n",
        "                wrongNs.append(i)\n",
        "\n",
        "        if len(wrongNs) == 0:\n",
        "          break\n",
        "        updateN = random.choice(wrongNs)\n",
        "\n",
        "        for i,weight in enumerate(linear_regression_weights):\n",
        "            linear_regression_weights[i] = linear_regression_weights[i] + y[updateN] * XWithBias[updateN][i]\n",
        "\n",
        "avg_runs = sum(numIterationsList)/runs\n",
        "print(f'Average runs until conversion : {avg_runs}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO9ZFT2lBIJL",
        "outputId": "bbf23215-fb7f-43f9-c1ad-24f56d56861d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average runs until conversion : 2.381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. a**\n",
        "The output is closest to 1."
      ],
      "metadata": {
        "id": "aegf_mGdDjFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nonlinear Transformation"
      ],
      "metadata": {
        "id": "oang8R22Fyf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x:np.ndarray):\n",
        "    return np.sign(x[0]**2+x[1]**2-0.6).astype(int)"
      ],
      "metadata": {
        "id": "c0amZhQzH1jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1000\n",
        "X = np.random.uniform(-1, 1, size=(n,2))\n",
        "Y = np.apply_along_axis(f, 1, X)\n",
        "\n",
        "noisyIdxs = np.random.choice(n, int(n/10), replace=False)\n",
        "for i in noisyIdxs:\n",
        "    Y[i] = np.negative(Y[i])\n",
        "\n",
        "XWithBias = np.insert(X, 0, 1, axis=1)\n",
        "XDagger = np.dot(np.linalg.inv(np.dot(XWithBias.T, XWithBias)), XWithBias.T)\n",
        "weightsFromLinearRegression = np.dot(XDagger, Y)\n",
        "YPred = np.sign(np.dot(XWithBias, weightsFromLinearRegression))\n"
      ],
      "metadata": {
        "id": "mqcOyNTCELpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runs = 1000\n",
        "eIns = []\n",
        "\n",
        "for _ in range(runs):\n",
        "    X = np.random.uniform(-1, 1, size=(n,2))\n",
        "    def f(x:np.ndarray):\n",
        "        return np.sign(x[0]**2+x[1]**2-0.6).astype(int)\n",
        "    Y = np.apply_along_axis(f, 1, X)\n",
        "\n",
        "    # Simulate noise by flipping sign in random 10% of Y\n",
        "    noisyIdxs = np.random.choice(n, int(n/10), replace=False)\n",
        "    for i in noisyIdxs:\n",
        "        Y[i] = np.negative(Y[i])\n",
        "\n",
        "    XWithBias = np.insert(X, 0, 1, axis=1)\n",
        "\n",
        "    # Let's apply linear regression\n",
        "    XDagger = np.dot(np.linalg.inv(np.dot(XWithBias.T, XWithBias)), XWithBias.T)\n",
        "    weightsFromLinearRegression = np.dot(XDagger, Y)\n",
        "\n",
        "    # Make predictions from our linear regression weights\n",
        "    YPred = np.sign(np.dot(XWithBias, weightsFromLinearRegression))\n",
        "\n",
        "    # And check how many we errorz\n",
        "    eIn = sum(YPred != Y) / n\n",
        "    eIns.append(eIn)\n",
        "\n",
        "avg_e_in = sum(eIns)/runs\n",
        "print(f'\\nEstimated eIn avg: {avg_e_in}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkLaEB-kENW-",
        "outputId": "0264d265-d7e1-4f86-da91-f7cd053ef0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Estimated eIn avg: 0.5056669999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. d**\n",
        "The output is closest to 0.5."
      ],
      "metadata": {
        "id": "9jAQNKSCEvRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1000\n",
        "runs = 1000\n",
        "\n",
        "e_In_A = []\n",
        "e_In_B = []\n",
        "e_In_C = []\n",
        "e_In_D = []\n",
        "e_In_E = []\n",
        "\n",
        "weightsA = np.array([-1, -0.05, 0.08, 0.13, 1.5, 1.5])\n",
        "weightsB = np.array([-1, -0.05, 0.08, 0.13, 1.5, 15])\n",
        "weightsC = np.array([-1, -0.05, 0.08, 0.13, 15, 1.5])\n",
        "weightsD = np.array([-1, -1.5, 0.08, 0.13, 0.05, 0.05])\n",
        "weightsE = np.array([-1, -0.05, 0.08, 1.5, 0.15, 0.15])\n",
        "\n",
        "def get_e_in(weights, X, YLinReg):\n",
        "  y = np.sign(np.dot(X, weights))\n",
        "  e_in = sum(y != YLinReg) / n\n",
        "  return e_in\n",
        "\n",
        "for _ in range(runs):\n",
        "    X = np.random.uniform(-1, 1, size=(n,2))\n",
        "    x1s = X[:,0]\n",
        "    x2s = X[:,1]\n",
        "\n",
        "    Y = np.apply_along_axis(f, 1, X)\n",
        "    X = np.array([ np.ones(n), x1s, x2s, x1s*x2s, x1s**2, x2s**2 ]).T\n",
        "\n",
        "    XDagger = np.dot(np.linalg.inv(np.dot(X.T, X)), X.T)\n",
        "    linRegWeights = np.dot(XDagger, Y)\n",
        "    YLinReg = np.sign(np.dot(X, linRegWeights))\n",
        "\n",
        "\n",
        "    eInA = get_e_in(weightsA, X, YLinReg)\n",
        "    eInB = get_e_in(weightsB, X, YLinReg)\n",
        "    eInC = get_e_in(weightsC, X, YLinReg)\n",
        "    eInD = get_e_in(weightsD, X, YLinReg)\n",
        "    eInE = get_e_in(weightsE, X, YLinReg)\n",
        "\n",
        "    e_In_A.append(eInA)\n",
        "    e_In_B.append(eInB)\n",
        "    e_In_C.append(eInC)\n",
        "    e_In_D.append(eInD)\n",
        "    e_In_E.append(eInE)\n",
        "\n",
        "print(f'A: {sum(e_In_A)/runs}\\n')\n",
        "print(f'B: {sum(e_In_B)/runs}\\n')\n",
        "print(f'C: {sum(e_In_C)/runs}\\n')\n",
        "print(f'D: {sum(e_In_D)/runs}\\n')\n",
        "print(f'E: {sum(e_In_E)/runs}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcMMOJq-ExvQ",
        "outputId": "3854974c-c9a7-454a-c3d0-23f809afb73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: 0.03331399999999993\n",
            "\n",
            "B: 0.3360840000000005\n",
            "\n",
            "C: 0.3363100000000004\n",
            "\n",
            "D: 0.3684570000000002\n",
            "\n",
            "E: 0.4400480000000002\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. a**\n",
        "A is closest."
      ],
      "metadata": {
        "id": "QNG-TsXRE_JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x:np.ndarray):\n",
        "    return np.sign(x[0]**2+x[1]**2-0.6).astype(int)"
      ],
      "metadata": {
        "id": "9wxV_y5lIAnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1000\n",
        "runs = 1000\n",
        "\n",
        "eOuts = []\n",
        "weights = np.array([-1, -0.05, 0.08, 0.13, 1.5, 1.5])\n",
        "for _ in range(runs):\n",
        "    X = np.random.uniform(-1, 1, size=(n,2))\n",
        "    x1s = X[:,0]\n",
        "    x2s = X[:,1]\n",
        "\n",
        "    Y = np.apply_along_axis(f, 1, X)\n",
        "\n",
        "    noisyIdxs = np.random.choice(n, int(N/10), replace=False)\n",
        "    for i in noisyIdxs:\n",
        "        Y[i] = np.negative(Y[i])\n",
        "\n",
        "    X = np.array([ np.ones(n), x1s, x2s, x1s*x2s, x1s**2, x2s**2 ]).T\n",
        "    YPred = np.sign(np.dot(X, weights))\n",
        "\n",
        "\n",
        "    eOut = sum(YPred != Y) / n\n",
        "    eOuts.append(eOut)\n",
        "\n",
        "e_out = sum(eOuts) / runs\n",
        "print(f'Estimated eOut : {e_out}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "379HF5z8FBd3",
        "outputId": "8ad53904-bec2-4649-9f50-f19c936b4811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated eOut : 0.14257200000000023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. b**\n",
        "The output is closest to 0.1."
      ],
      "metadata": {
        "id": "XnP5kEGnFFxK"
      }
    }
  ]
}