{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overfitting and Deterministic Noise"
      ],
      "metadata": {
        "id": "yTu30x9bnKh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. b"
      ],
      "metadata": {
        "id": "ixZnNgo-ns3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deterministic Noise will increase. Since we know that Deterministic noise depends on $H$ and that $H'$ is a subset of $H$, the noise will only get bigger."
      ],
      "metadata": {
        "id": "GhVYpuJ5ow1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularization with Weight Decay"
      ],
      "metadata": {
        "id": "zOBxipwrnPyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "Xk6c4P0tqZku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "with open('train.txt','r') as train_file:\n",
        "    for line in train_file:\n",
        "        train_data.append([float(index) for index in line.split()])\n",
        "train_data = np.asarray(train_data)"
      ],
      "metadata": {
        "id": "rbfocjHGuT3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "with open('test.txt','r') as test_file:\n",
        "    for line in test_file:\n",
        "        test_data.append([float(index) for index in line.split()])\n",
        "test_data = np.asarray(test_data)"
      ],
      "metadata": {
        "id": "C2li7wbcuZ0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nonlinear_transform(X):\n",
        "    new_X = []\n",
        "    for x in X:\n",
        "        x1 = x[0]\n",
        "        x2 = x[1]\n",
        "        new_x = [1, x1, x2, x1**2, x2**2, x1*x2, np.abs(x1-x2), np.abs(x1+x2)]\n",
        "        new_X.append(new_x)\n",
        "    return np.asarray(new_X)"
      ],
      "metadata": {
        "id": "8oga-JNtuhLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lin_reg(X, y):\n",
        "    X_plus = np.linalg.inv(X.transpose().dot(X)).dot(X.transpose())\n",
        "    w = X_plus.dot(y)\n",
        "    return(w)"
      ],
      "metadata": {
        "id": "Bcw3oGTMui0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def class_err(X, w, y):\n",
        "    correct_idx = []\n",
        "    count = 0\n",
        "    for x in X:\n",
        "        if np.sign(w.dot(x)) == y[count]:\n",
        "            correct_idx.append(count)\n",
        "        count += 1\n",
        "    class_err = 1-len(correct_idx)/float(count)\n",
        "    return class_err"
      ],
      "metadata": {
        "id": "TPK48kzsuncz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. a"
      ],
      "metadata": {
        "id": "8WKHOuoInwg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data[:,:2]\n",
        "y = train_data[:,2]\n",
        "Z = nonlinear_transform(X)\n",
        "w = lin_reg(Z,y)\n",
        "in_sample_err = class_err(Z,w,y)\n",
        "print(f'In Sample Error: {in_sample_err}')\n",
        "\n",
        "test_X = test_data[:,:2]\n",
        "test_Z = nonlinear_transform(test_X)\n",
        "test_y = test_data[:,2]\n",
        "test_err = class_err(test_Z,w,test_y)\n",
        "print(f'Out of Sample Error: {test_err}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogx4hh5auw7J",
        "outputId": "2ae912a1-271c-4963-c45c-f14e6dc2e9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In Sample Error: 0.02857142857142858\n",
            "Out of Sample Error: 0.08399999999999996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. d"
      ],
      "metadata": {
        "id": "X5RstH7gnxVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lin_reg_weights(X, y, l):\n",
        "    X_plus = np.linalg.inv(X.transpose().dot(X) + l*np.eye(X.shape[1])).dot(X.transpose())\n",
        "    w = X_plus.dot(y)\n",
        "    return(w)"
      ],
      "metadata": {
        "id": "cd3LenDbukcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = -3\n",
        "l = 10**k\n",
        "X = train_data[:,:2]\n",
        "X = nonlinear_transform(X)\n",
        "y = train_data[:,2]\n",
        "w = lin_reg_weights(X,y,l)\n",
        "in_sample_err = class_err(X,w,y)\n",
        "print(f'In Sample Error: {in_sample_err}')\n",
        "\n",
        "test_X = nonlinear_transform(test_data[:,:2])\n",
        "test_y = test_data[:,2]\n",
        "test_err = class_err(test_X,w,test_y)\n",
        "print(f'Out of Sample Error: {test_err}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0VfI4Iou1aX",
        "outputId": "4cef6a03-9951-463c-f7f2-40d2cb1c6bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In Sample Error: 0.02857142857142858\n",
            "Out of Sample Error: 0.07999999999999996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. e"
      ],
      "metadata": {
        "id": "9qT-iFGDnyD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "l = 10**k\n",
        "X = train_data[:,:2]\n",
        "X = nonlinear_transform(X)\n",
        "y = train_data[:,2]\n",
        "w = lin_reg_weights(X,y,l)\n",
        "in_sample_err = class_err(X,w,y)\n",
        "print(f'In Sample Error: {in_sample_err}')\n",
        "\n",
        "test_X = nonlinear_transform(test_data[:,:2])\n",
        "test_y = test_data[:,2]\n",
        "test_err = class_err(test_X,w,test_y)\n",
        "print(f'Out of Sample Error: {test_err}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkr--a5nu8HF",
        "outputId": "3dc2b378-25a8-4414-a7c3-ef496eff8483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In Sample Error: 0.37142857142857144\n",
            "Out of Sample Error: 0.43600000000000005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. d"
      ],
      "metadata": {
        "id": "8e4MNZNjnzqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = -2\n",
        "for k in [2,1,0,-1,-2]:\n",
        "    l = 10**k\n",
        "    X = train_data[:,:2]\n",
        "    X = nonlinear_transform(X)\n",
        "    y = train_data[:,2]\n",
        "    w = lin_reg_weights(X,y,l)\n",
        "    in_sample_err = class_err(X,w,y)\n",
        "\n",
        "    test_X = nonlinear_transform(test_data[:,:2])\n",
        "    test_y = test_data[:,2]\n",
        "    test_err = class_err(test_X,w,test_y)\n",
        "    print(f'k: {k}, Error: {test_err}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIkDSp6hu9Wy",
        "outputId": "60b07e6b-6d30-4b6f-899f-48953351b0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k: 2, Error: 0.22799999999999998\n",
            "k: 1, Error: 0.124\n",
            "k: 0, Error: 0.09199999999999997\n",
            "k: -1, Error: 0.05600000000000005\n",
            "k: -2, Error: 0.08399999999999996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. b"
      ],
      "metadata": {
        "id": "f9hXFbdhn16P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Value closest when $k = -1$. Error is roughly $0.06$."
      ],
      "metadata": {
        "id": "AauBSQknEAmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularization for Polynomials"
      ],
      "metadata": {
        "id": "KRKcYFgunUuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. c"
      ],
      "metadata": {
        "id": "cKwM8u8vn1-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the above definitions, we know that $H(10,0,3) = \\{h|h(x) = ∑_{q=0}^{10} w_qL_q(x), w_q = 0$ for $q \\geq 3\\} = \\{h|h(x) = ∑_{q=0}^{2} w_qL_q(x)\\} = H_2$. We also know that $H(10,0,4) = H_3$ by the same process. Since $H(10,0,3)$ is inlcu"
      ],
      "metadata": {
        "id": "7_k7l_sbuJs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks"
      ],
      "metadata": {
        "id": "tMSuAEg2nZVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. d"
      ],
      "metadata": {
        "id": "qqkbHDZen7MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The total number of operations is given by the forward propagation + backpropagation + updating weights.\n",
        "\n",
        "\n",
        "Forward propagation is given by:\n",
        "\n",
        "$x_j^{(l)} = θ(∑_{i=0}^{d^{(l-1)}} w_{ij}^{(l)}x_{i}^{(l-1)})$. For $l = 1$, we have $6 \\cdot 3 = 18$ operations and for $l = 2$, we have $4 \\cdot 1 = 4$ operations. The total forward propagation operations is $22$.\n",
        "\n",
        "Back propagation is given by:\n",
        "\n",
        "$\\delta_i^{(l-1)} = (1-(x_i^{(l-1)})^2)(∑_{j=1}^{d^{(l)}} w_{ij}^{(l)}\\delta_{j}^{(l)})$. $For $l = 2$, we have $3 \\cdot 1 = 3$ operations.\n",
        "\n",
        "Updating weights is given by:\n",
        "\n",
        "$w_{ij}^{(l)} = w_{ij}^{(l)} - ηx_i^{(l-1)}δ_J^{(l)}$. For each $l$, we have $1$ operation. There are $22$ in total.\n",
        "\n",
        "Thus the total operations is given by $22 + 3 + 22 = 47$."
      ],
      "metadata": {
        "id": "jKMF88Tc-1ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. a"
      ],
      "metadata": {
        "id": "GN8ilgn2n_nb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the minimum possible number of weights for the network, we must have 2 units for every hidden layer. After the 10 input units, we have 18 total hidden layers for the 36 hidden units. Each layer has 2 units and therefore 2 connections and 2 weights. Therefore the minimum number of weights is given by $10 + 18 \\cdot 2 = 46$."
      ],
      "metadata": {
        "id": "aJoQormwCVbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. e"
      ],
      "metadata": {
        "id": "3GstDbo9oARS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the maximum possible number of weights, we need to maximize the equation: $w = 10 (h - 1) + h \\cdot (36 - h - 1) + (36 - h)$ where $h$ is the number of nodes in the first layer. Using Mathematica to maximize this function, we get a maximum when $h = 22$ nodes. In this case $w = 510$."
      ],
      "metadata": {
        "id": "oVlFbcxKDG4x"
      }
    }
  ]
}